{
  "query": "machine learning healthcare",
  "pipeline_summary": {
    "total_papers": 20,
    "with_pmcids": 0,
    "with_fulltext_potential": 0,
    "downloaded_pdfs": 0,
    "extracted_text": 0,
    "success_rates": {
      "pmcid_conversion": 0.0,
      "pdf_download": 0,
      "text_extraction": 0
    }
  },
  "papers": [
    {
      "pmid": "PMID:40996687",
      "pmcid": null,
      "title": "Risk of Progression and Costs of Care for Patients with Type 2 Diabetes and Chronic Kidney Disease.",
      "journal": "Diabetes therapy : research, treatment and education of diabetes and related disorders",
      "abstract": "INTRODUCTION: Chronic kidney disease (CKD) progression is associated with a significant incremental economic burden. Previous work has demonstrated high accuracy of the laboratory-based machine learning model, Klinrisk, in predicting the risk of CKD progression. We sought to use the Klinrisk model to evaluate the association of risk of CKD progression with healthcare resource utilization (HRU) and costs of care in adults with type 2 diabetes and CKD. METHODS: This retrospective observational study included 413,177 eligible patients from Optum's electronic health records database (1/1/2007-9/30/2022). Patients were classified into low-, medium-, and high-risk groups based on their 2-year risk of CKD progression as predicted by the Klinrisk model. All-cause HRU and medical costs during the 1\u00a0year after CKD were estimated for each group. RESULTS: Of the 413,177 patients included, 110,399 (26.7%) were classified as low-risk of CKD progression, 253,188 (61.3%) as medium-risk, and 49,590 (12.0%) as high-risk. The observed risk of CKD progression at 2\u00a0years, 5\u00a0years, and 10\u00a0years was 18.6%, 36.5%, and 54.1% for high-risk patients, 3.7%, 11.7%, and 26.4% for medium-risk patients, and 1.5%, 5.7%, and 15.8% for low-risk patients, which were similar to the predicted risks of CKD progression. High-risk patients had higher HRU and more than 2-3 times higher costs than lower-risk patients. Inpatient costs were the major cost driver for high-risk patients. CONCLUSIONS: The Klinrisk model accurately identified patients with type 2 diabetes and CKD requiring the most healthcare resources. Such tools can support the identification and targeting of high-risk patients for interventions that may lead to a more cost-effective model of care.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40996410",
      "pmcid": null,
      "title": "[Digital twins: an innovative and promising option to optimize care pathways for older patients].",
      "journal": "Geriatrie et psychologie neuropsychiatrie du vieillissement",
      "abstract": "The digital transformation of healthcare, which has been continuously evolving for over two decades, has recently paved the way for major innovations, notably through the emergence of the digital twin (DT) concept. Originating from self-supervised machine learning, the DT involves creating a virtual replica (virtual product) of a patient, organ, or healthcare system (real product) to predict its evolution based on real-life data. It is based on clinical, biological, environmental data, as well as data from sensors and medico-administrative databases (e.g., SNDS) and relies on various digital technologies. Initially applied in aerospace, industry, and agriculture, DTs have recently gained traction in healthcare, particularly for the personalization of care plans and pathways. In geriatrics, DTs could help model the functional or clinical evolution of older adults, optimize healthcare resources, and adapt therapeutic protocols. The development of DTs in geriatrics involves addressing several major challenges, including older adults' acceptance of technology, building multidisciplinary teams, accurately modelling the complexity of aging, and considering the environmental impact of DT technologies. In summary, the digital twin represents a promising tool to support healthy aging and care pathways, provided its clinical integration and social acceptability are strengthened.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40996387",
      "pmcid": null,
      "title": "Stroke Mortality in Kazakhstan: Comparison of National Health Records to Global Burden of Disease Study.",
      "journal": "JACC. Asia",
      "abstract": "BACKGROUND: Stroke is a major public health concern requiring valid estimates for planning and evaluating health interventions. The GBD (Global Burden of Disease) studies have become a major source of information; however, data sources have historically been a limitation. OBJECTIVES: We sought to compare stroke mortality estimates in Kazakhstan with those reported by the GBD study. METHODS: Mortality data were extracted from the Unified Electronic Healthcare System of Kazakhstan (UNEHS). We used the autoregressive integrated moving average (ARIMA), Bayesian structural time-series (BSTS), and Extreme Gradient Boosting (XGBoost) to model data from the UNEHS and forecast its trends until 2030. The accuracy metrics were mean absolute error, root mean square error, and mean absolute percentage error. We calculated the standardized difference in mortality estimates between the databases for the observed and forecasted estimates. RESULTS: The BSTS, ARIMA, and XGBoost models revealed slight variations in accuracy metrics, which depended on forecasting horizons and mostly favored XGBoost. During 2014-2030, the absolute difference in death counts was 207,108 between the GBD and UNEHS. The GBD estimates were twice as many across both the observed and predicted periods, with a moderate standardized difference (0.73) when considering their average. This study showed a systematic difference between GBD and national data. CONCLUSIONS: We found that UNEHS estimates were not comparable despite our efforts to replicate the GBD methods. Further studies are needed to explore the discrepancies between the national or regional data and GBD. Current limitations related to primary data and reproducibility require caution when interpreting GBD findings.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40995249",
      "pmcid": null,
      "title": "Artificial Intelligence in the Management of Polypharmacy Among Older Adults: A Scoping Review.",
      "journal": "Cureus",
      "abstract": "The advent of artificial intelligence (AI) presents an opportunity to enhance the management of multiple medications for patients. Despite the growing body of research on the clinical impact and accuracy of AI in healthcare, current literature is limited in addressing AI's role in medication management for older adults. The goal of this scoping review was to assess the extent and applicability of AI applications in managing multiple pharmacological therapies among adults aged 50 and older. Relevant articles were searched in EMBASE, Ovid MEDLINE, and Web of Science databases. Search phrases included \"polypharmacy/polytherapy\", \"artificial intelligence in healthcare\", \"machine learning/language learning\", and \"elderly populations\". The search initially identified 58 citations. After a systemized and rigorous screening process, 12 articles were further screened for eligibility and critically appraised for bias and appropriateness. Of those, a total of five articles were retained for the final analysis. They focused on the application of AI and web-based applications to reduce inappropriate medication use and drug interactions, how machine learning and audio-based activity recognition systems could improve medication adherence among older adults, and recognizable patterns between multimorbidity and polypharmacy in elderly populations with chronic illnesses. The main findings of this review suggested that AI tools have demonstrated efficiency and accuracy in eliminating drug-drug interactions, assisting in the detection of potentially inappropriate medications (PIMs), and identifying patterns of multimorbidity due to polypharmacy in older adults. Moreover, AI tools were considered easy to use and helped enhance medication adherence. Results suggest that AI has potential in managing polypharmacy, particularly in enhancing medication safety, improving adherence, and predicting risk factors for medication-related errors in older adults. Future investigations are needed that focus on AI's long-term effect on patient outcomes, its role in personalized pharmacotherapy, and ongoing challenges related to algorithmic transparency, bias mitigation, and regulatory oversight. As AI continues to evolve, its integration into healthcare would benefit from methodical evaluation, stringent oversight, and interdisciplinary collaboration to ensure its safe and effective deployment in patient care.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40995078",
      "pmcid": null,
      "title": "Artificial intelligence in proliferative diabetic retinopathy: advancing diagnosis, precision surgery, and anti-VEGF therapy optimization.",
      "journal": "Frontiers in medicine",
      "abstract": "Proliferative diabetic retinopathy (PDR) represents the most advanced and vision-threatening stage of diabetic retinopathy (DR) and remains a leading cause of blindness in individuals with diabetes. This review presents a comprehensive overview of recent advances in the application of artificial intelligence (AI) for the diagnosis and treatment of PDR, emphasizing its clinical potential and associated challenges. The role of vascular endothelial growth factor (VEGF) in the pathogenesis of PDR has become increasingly clear, and AI offers novel capabilities in retinal image analysis, disease progression prediction, and treatment decision-making. These advancements have notably improved diagnostic accuracy and efficiency. Furthermore, AI-based models show promise in optimizing anti-VEGF therapy by enhancing therapeutic outcomes while reducing unnecessary healthcare expenditures. Future research should focus on the safe, effective, and ethical integration of AI into clinical workflows. Overcoming practical deployment barriers will require interdisciplinary collaboration among technology developers, clinicians, and regulatory bodies. The strategies and frameworks discussed in this review are expected to provide a foundation for future AI research and clinical translation in fields of PDR.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40994792",
      "pmcid": null,
      "title": "A Scoping Review of Artificial Intelligence-Based Health Education Interventions for Patients with Type 2 Diabetes.",
      "journal": "Diabetes, metabolic syndrome and obesity : targets and therapy",
      "abstract": "BACKGROUND: Type 2 diabetes mellitus (T2DM) poses a critical global health burden, requiring effective health education to enhance patient self-management. Artificial intelligence (AI) offers personalized and scalable solutions; however, comprehensive syntheses of its applications in T2DM health education are scarce. OBJECTIVE: Guided by the Arksey and O'Malley scoping review framework, this study maps AI-based health education interventions for T2DM by evaluating technologies, effectiveness, and challenges. METHODS: Seven academic databases (PubMed, Web of Science, Embase, Scopus, EBSCO, the Cochrane Library, the Joanna Briggs Institute (JBI) Database, and Wiley Online Library)\u00a0were searched for studies published from 2008 to March 2025, identifying 14 eligible interventional studies involving 32,478 adult T2DM patients receiving AI-based health education. RESULTS: (1) Technological Diversity: Interventions included mobile apps (eg, FoodLens, TRIO system), chatbots, intelligent platforms, and machine learning algorithms, focusing on diet, glucose monitoring, and lifestyle management. (2) Effectiveness: AI interventions enhanced glycemic control, yielding reductions in glycosylated hemoglobin (HbA1c) of up to 2.59%, improved self\u2011management adherence (60-85%), and produced positive psychological outcomes (eg, increased self\u2011efficacy); efficacy varied by intervention duration and user engagement. (3) Challenges: Key barriers included technical complexity, low long-term engagement, digital literacy gaps, and data privacy concerns. CONCLUSION: AI holds substantial potential for T2DM health education via personalized, accessible interventions. Future research should address technological hurdles, prioritize user-centered design, and integrate AI into healthcare systems to ensure sustainability and equity.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40994463",
      "pmcid": null,
      "title": "Web-Based Botnet for Blocking Control Flow in Open-Source Medical Syringe Pump.",
      "journal": "International journal of grid and utility computing",
      "abstract": "Integrating open-source medical systems, with advancements in 3D printing technology and microcomputer systems such as Arduino and Raspberry Pi, has revolutionized the healthcare industry. However, it has also exposed cybersecurity vulnerabilities in hospitals. This paper presents a web-based botnet as a proof-of-concept to demonstrate potential disruptions in the control flow of a syringe pump in an IoT medical network testbed. Our lightweight botnet stands out for its rapid deployment and minimal use of resources. We also provide a publicly available dataset from this botnet for cybersecurity research on open-source medical systems. Additionally, we developed a methodology for feature selection to detect botnet attacks. Our comparative study with various machine learning algorithms revealed the best strategy for detecting these attacks using network traffic data from benign and malicious environments. The results were impressive, with our feature selection technique achieving over 99% accuracy on the testing dataset, successfully identifying 63,380 out of 63,382 attack instances.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40994240",
      "pmcid": null,
      "title": "Racing Against the Algorithm: Leveraging Inclusive AI as an Antiracist Tool for Brain Health.",
      "journal": "Clinical and translational science",
      "abstract": "Artificial intelligence (AI) is transforming medicine, including neurology and mental health. Yet without equity-centered design, AI risks reinforcing systemic racism. This article explores how algorithmic bias and phenotypic exclusion disproportionately affect marginalized communities in brain health. Drawing on lived experience and scientific evidence, the essay outlines five design principles-centered on inclusion, transparency, and accountability-to ensure AI promotes equity. By reimagining AI as a tool for justice, we can reshape translational science to serve all populations.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993827",
      "pmcid": null,
      "title": "Construction and validation of a machine learning-based model predicting early readmission in patients with decompensated cirrhosis: a prospective two-center cohort study.",
      "journal": "BioData mining",
      "abstract": "BACKGROUND: Early 30-day readmission remains a significant burden on the socioeconomic and healthcare system in the context of decompensated cirrhosis. Early recognition and accurate identification are crucial. However, current evidence is elusive and traditional scores concerning liver disease severity are lacking specificity and sensitivity. We sought to construct and validate an explainable machine learning (ML)-based prediction model, and evaluate its prognostic implementation in patients readmitted due to acute episodes. The prediction model for discovery and validation was based on a two-center prospective investigation. Our discovery sample, comprising 636 patients with cirrhosis, was divided into a training set and a test set, with an additional cohort of 150 patients serving as an external validation. Eleven ML methods were performed to establish an indicative model based on a variety of easily accessible and obtainable variables from the electronic health record. The area under the ROC curve (AUC), alongside several evaluation parameters, was used for comparison regarding predictive performance. Considering feature importance and final model explanation, we adopted the SHapley Additive exPlanation method for ranking. Furthermore, prognostic implementation was verified by subgrouping according to the final model and clinical outcomes during follow-up. RESULTS: Among all 11 ML algorithms, the random forest (RF) algorithm represented the best discriminatory capability. Processing feature reduction generated a final 7-feature RF model with explainability based on the importance ranking. Our constructed model was of moderately accurate prediction pertaining to internal and external validations, with respective AUCs of 0.853 and 0.838, which was further transformed into an online tool to facilitate daily practice. Patients positively adjudged by the prediction model had aggravated underlying disease severity and poor psychophysiologic reservation. CONCLUSIONS: The final explainable ML model was capable of predicting early readmission and was closely connected with adverse outcomes in individual patients experiencing decompensated cirrhosis. Notably, it allayed the \"black-box\" concerns inherent to ML techniques with an indirect interpretation.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993533",
      "pmcid": null,
      "title": "Development of a machine learning-based depression risk identification tool for older adults with asthma.",
      "journal": "BMC psychiatry",
      "abstract": "BACKGROUND: Asthma is a chronic inflammatory disorder that adversely affects the quality of life, particularly in older adults. The coexistence of depression in asthma patients complicates their management and exacerbates health outcomes. This study aims to develop a machine learning-based Depression Risk Identification Tool (DRIT) to predict depression risk in this population. METHODS: We conducted a secondary analysis of data from the China Health and Retirement Longitudinal Study (CHARLS), including 1154 asthma patients. Using LASSO regression, we identified 21 significant predictors of depression. We evaluated eight machine learning algorithms, including the glmBoost model, which was selected based on performance metrics such as accuracy and area under the ROC curve (AUC). RESULTS: The glmBoost model demonstrated superior predictive performance, achieving an AUC of 0.740 (95% CI: 0.674-0.804) in the testing cohort and 0.664 (95% CI: 0.614-0.714) in the validation cohort. Key risk factors identified included poor cognitive function, heavy exercise, unmarried status, and female gender. The model's interpretability was enhanced using SHAP values, providing insights into the contributions of each predictor. LIMITATIONS: The study's reliance on survey data may limit the comprehensiveness of risk factor identification. Additionally, the applicability of findings may vary across different populations, necessitating further validation in diverse cohorts. CONCLUSION: The DRIT effectively predicts depression risk among older asthma patients, enabling timely identification and intervention. This tool has the potential to improve patient outcomes and reduce the burden on healthcare systems by facilitating integrated management of asthma and depression.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993504",
      "pmcid": null,
      "title": "Deep Learning-based Gait Recognition and Evaluation of the Wounded.",
      "journal": "Disaster medicine and public health preparedness",
      "abstract": "OBJECTIVES: Remote injury assessment during natural disasters poses major challenges for healthcare providers due to the inaccessibility of disaster sites. This study aimed to explore the feasibility of using artificial intelligence (AI) techniques for rapid assessment of traumatic injuries based on gait analysis. METHODS: We conducted an AI-based investigation using a dataset of 4500 gait images across 3 species: humans, dogs, and rabbits. Each image was categorized as either normal or limping. A deep learning model, YOLOv5-a state-of-the-art object detection algorithm-was trained to identify and classify limping gait patterns from normal ones. Model performance was evaluated through repeated experiments and statistical validation. RESULTS: The YOLOv5 model demonstrated high accuracy in distinguishing between normal and limp gaits across species. Quantitative performance metrics confirmed the model's reliability, and qualitative case studies highlighted its potential application in remote, fast traumatic assessment scenarios. CONCLUSIONS: The use of AI, particularly deep convolutional neural networks like YOLOv5, shows promise in enabling fast, remote traumatic injury assessment during disaster response. This approach could assist healthcare professionals in identifying injury risks when physical access to patients is restricted, thereby improving triage efficiency and early intervention.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993477",
      "pmcid": null,
      "title": "Ethical Considerations in Patient Privacy and Data Handling for AI in Cardiovascular Imaging and Radiology.",
      "journal": "Journal of imaging informatics in medicine",
      "abstract": "The integration of artificial intelligence (AI) into cardiovascular imaging and radiology offers the potential to enhance diagnostic accuracy, streamline workflows, and personalize patient care. However, the rapid adoption of AI has introduced complex ethical challenges, particularly concerning patient privacy, data handling, informed consent, and data ownership. This narrative review explores these issues by synthesizing literature from clinical, technical, and regulatory perspectives. We examine the tensions between data utility and data protection, the evolving role of transparency and explainable AI, and the disparities in ethical and legal frameworks across jurisdictions such as the European Union, the USA, and emerging players like China. We also highlight the vulnerabilities introduced by cloud computing, adversarial attacks, and the use of commercial datasets. Ethical frameworks and regulatory guidelines are compared, and proposed mitigation strategies such as federated learning, blockchain, and differential privacy are discussed. To ensure ethical implementation, we emphasize the need for shared accountability among clinicians, developers, healthcare institutions, and policymakers. Ultimately, the responsible development of AI in medical imaging must prioritize patient trust, fairness, and equity, underpinned by robust governance and transparent data stewardship.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993402",
      "pmcid": null,
      "title": "Measuring the semantic priming effect across many languages.",
      "journal": "Nature human behaviour",
      "abstract": "Semantic priming has been studied for nearly 50 years across various experimental manipulations and theoretical frameworks. Although previous studies provide insight into the cognitive underpinnings of semantic representations, they have suffered from small sample sizes and a lack of linguistic and cultural diversity. In this Registered Report, we measured the size and the variability of the semantic priming effect across 19 languages (n\u2009=\u200925,163 participants analysed) by creating the largest available database of semantic priming values using an adaptive sampling procedure. We found evidence for semantic priming in terms of differences in response latencies between related word-pair conditions and unrelated word-pair conditions. Model comparisons showed that the inclusion of a random intercept for language improved model fit, providing support for variability in semantic priming across languages. This study highlights the robustness and variability of semantic priming across languages and provides a rich, linguistically diverse dataset for further analysis. The Stage 1 protocol for this Registered Report was accepted in principle on 15 July 2022. The protocol, as accepted by the journal, can be found at https://osf.io/u5bp6 (registration) or https://osf.io/q4fjy (preprint version 6, 31 May 2022).",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40993299",
      "pmcid": null,
      "title": "Expanding care coordination in an integrated health system through causal machine learning.",
      "journal": "NPJ digital medicine",
      "abstract": "Hospital readmission is a key quality metric, yet post-discharge interventions often yield variable results. In the first large-scale randomized evaluation of causal machine learning in a health system, we assessed whether a novel model (the Predicted Benefit Intervention (PBI) score) could identify lower-risk patients most likely to benefit from post-discharge care coordination within Kaiser Permanente Northern California (KPNC). From May to December 2022, 9959 low-risk patients at 19 KPNC hospitals were randomized to usual care or the Transitions Program, which included medication reconciliation, primary care follow-up scheduling, and weekly calls for 30 days. While 30-day readmissions declined in the intervention group (7.7% vs. 8.2%), the difference was not statistically significant. However, the observed-to-expected readmission ratio declined into randomization and remained low thereafter; this decline was statistically significant. This study demonstrates the feasibility of implementing causal machine learning at scale to improve targeting and resource allocation in care delivery.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40992790",
      "pmcid": null,
      "title": "Interpreting psychiatric digital phenotyping data with large language models: a preliminary analysis.",
      "journal": "BMJ mental health",
      "abstract": "BACKGROUND: Digital phenotyping provides passive monitoring of behavioural health but faces implementation challenges in translating complex multimodal data into actionable clinical insights. Digital navigators, healthcare staff who interpret patient data and relay findings to clinicians, provide a solution, but workforce limitations restrict scalability. OBJECTIVE: This study provides one of the first systematic evaluation of large language model performance in interpreting simulated psychiatric digital phenotyping data, establishing baseline accuracy metrics for this emerging application. METHODS: We evaluated GPT-4o and GPT-3.5-turbo across over 153 test cases covering various clinical scenarios, timeframes and data quality levels using simulated test datasets currently employed in training human digital navigators. Performance was assessed on the model's capacity to identify clinical patterns relative to human digital navigation experts. FINDINGS: GPT-4o demonstrated 52% accuracy (95%\u2009CI 46.5% to 57.6%) in identifying clinical patterns based on standard test cases, significantly outperforming GPT-3.5-turbo (12%, 95%\u2009CI 8.4% to 15.6%). When analysing GPT-4o's performance across different scenarios, strongest results were observed for worsening depression (100%) and worsening anxiety (83%) patterns while weakest performance was seen for increased home time with improving symptoms (6%). Accuracy declined with decreasing data quality (69% for high-quality data vs 39% for low-quality data) and shorter timeframes (60% for 3-month data vs 43% for 3-week data). CONCLUSIONS: GPT-4o's 52% accuracy in zero-shot interpretation of psychiatric digital phenotyping data establishes a meaningful baseline, though performance gaps and occasional hallucinations confirm human oversight in digital navigation tasks remains essential. The significant performance variations across models, data quality levels and clinical scenarios highlight the need for careful implementation. CLINICAL IMPLICATIONS: Large language models could serve as assistive tools that augment human digital navigators, potentially addressing workforce limitations while maintaining necessary clinical oversight in psychiatric digital phenotyping applications.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40992645",
      "pmcid": null,
      "title": "Enhancing Risk Stratification for Incident Systolic Heart Failure through Machine Learning and Natural Language Processing.",
      "journal": "American heart journal",
      "abstract": "BACKGROUND: Clinical guidelines advocate use of validated risk models in patients experiencing heart failure with reduced ejection fraction (HFrEF) to inform prognosis and assist with management. We developed models for worsening HF (WHF) hospitalizations and death within one year of incident HFrEF using data available within electronic health records (EHR). METHODS: Adults with incident HFrEF were identified from 2013 to 2022 within an integrated healthcare delivery system. We developed decision tree-based models to estimate risks of WHF hospitalization and death within one year of the incident HFrEF date. WHF hospitalizations were ascertained using validated natural language processing algorithms. We evaluated the models using cross-validation and measured final performance (i.e., model discrimination using area under the curve [AUC] and model calibration using the Brier score and calibration plots) on a contemporary hold-out test set of patients from 2021-2022. RESULTS: Among 28,292 adults with incident HFrEF, 17.3% experienced WHF hospitalization and 15.1% all-cause death at one year of follow-up. We observed an AUC of 0.698 (95% CI: 0.682-0.714) for WHF hospitalization and 0.849 (95% CI: 0.836-0.861) for death and calibrated with a wide range of predicted risks. In comparison, a claims-based risk score displayed an AUC of 0.577 (95% CI: 0.570-0.606) for WHF hospitalization and a smaller dynamic range. Of patients classified as high risk for WHF hospitalization, only 12.0% were receiving full guideline-directed medical therapy at 6 months after HFrEF diagnosis. CONCLUSION: Risk models derived using EHR-based data elements can predict both 1-year WHF hospitalization and all-cause mortality in adults with incident HFrEF more accurately than claims-based approaches. These models can be used to improve population management and better target personalized strategies of care.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40991937",
      "pmcid": null,
      "title": "Extension of the Consolidated Criteria for Reporting Qualitative Research Guideline to Large Language Models (COREQ+LLM): Protocol for a Multiphase Study.",
      "journal": "JMIR research protocols",
      "abstract": "BACKGROUND: Qualitative research provides essential insights into human behaviors, perceptions, and experiences in health sciences. The COREQ (Consolidated Criteria for Reporting Qualitative Research) checklist, published in 2007 and endorsed by the Enhancing the Quality and Transparency of Health Research Network, advanced transparency of qualitative research reporting. However, the recent integration of large language models (LLMs) into qualitative research introduces novel opportunities and methodological challenges that existing guidelines do not address. LLMs are increasingly applied to research design as well as processing, analysis, interpretation, and even direct interaction (\"conversing\") with qualitative data. However, their probabilistic nature, dependence on underlying training data, and susceptibility to hallucinations necessitate dedicated reporting to ensure transparency, reproducibility, and methodological validity. OBJECTIVE: This protocol outlines the methodological development process of COREQ+LLM, an extension to the COREQ checklist, to support transparent reporting of LLM use in qualitative research. The three main objectives are to (1) identify and categorize current applications of LLMs used as qualitative research tools, (2) assess how LLM use in qualitative studies in health care is reported in published studies, and (3) develop and refine reporting items for COREQ+LLM through a structured consensus process among international experts. METHODS: Following the Enhancing the Quality and Transparency of Health Research Network guidance for reporting guideline development, this study comprises 4 main phases. Phase 1 is a systematic scoping review of peer-reviewed literature from January 2020 to April 2025, examining the use and reporting of LLMs in qualitative research. The scoping review protocol was registered with the Open Science Framework on June 6, 2025, and will adhere to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines. Phase 2 will use a Delphi process to reach consensus on candidate items for inclusion in the COREQ+LLM checklist among an interdisciplinary international panel of experts. Phase 3 includes pilot testing, and phase 4 involves publication and dissemination. RESULTS: As of September 2025, the steering committee has been established, and the initial search strategy for the scoping review has identified 5049 records, with 4201 (83.20%) remaining after duplicate removal. Title and abstract screening is underway and will inform the initial draft of candidate checklist items. The COREQ+LLM extension is scheduled for completion by December 2025. CONCLUSIONS: The integration of LLMs in qualitative research requires dedicated reporting guidelines to ensure methodological rigor, transparency, and interpretability. COREQ+LLM will address current reporting gaps by offering specific guidance for documenting LLM integration in qualitative research workflows. The checklist will assist researchers in transparently documenting LLM use, support reviewers and editors in evaluating methodological quality, and foster trust in LLM-supported qualitative research. By December 2025, COREQ+LLM will provide a rigorously developed tool to enhance the transparency, validity, and reproducibility of LLM-supported qualitative studies. INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): DERR1-10.2196/78682.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40991191",
      "pmcid": null,
      "title": "Detection and classification of medical images using deep learning for chronic kidney disease.",
      "journal": "International urology and nephrology",
      "abstract": "Chronic kidney disease (CKD) is an advancing disease which significantly impacts global healthcare, requiring early detection and prompt treatment is required to prevent its advancement to end-stage renal disease. Conventional diagnostic methods tend to be invasive, lengthy, and costly, creating a demand for automated, precise, and efficient solutions. This study proposes a novel technique for identifying and classifying CKD from medical images by utilizing a Convolutional Neural Network based Crow Search (CNN based CS) algorithm. The method employs sophisticated pre-processing techniques, including Z-score standardization, min-max normalization and robust scaling to improve the input data's quality. Selection of features is carried out using the chi-square test, and the Crow Search Algorithm (CSA) further optimizes the feature set for the improvement of accuracy classification and effectivess. The CNN architecture is employed to capture complex patterns using deep learning methods to accurately classify CKD in medical pictures. The model optimized and examined using an open access Kidney CT Scan data set. It achieved 99.05% accuracy, 99.03% Area under the Receiver Operating Characteristic Curve (AUC-ROC), and 99.01% Area under the precision-recall curve (PR-AUC), along with high precision (99.04%), recall (99.02%), and F1-score (99.00%). The results show that the CNN-based CS method delivers high accuracy and improved diagnostic precision related to conventional machine learning techniques. By incorporating CSA for feature optimization, the approach minimizes redundancy and improves model interpretability. This makes it a promising tool for automated CKD diagnosis, contributing to the development of AI-driven medical diagnostics and providing a scalable solution for early detection and management of CKD.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40991166",
      "pmcid": null,
      "title": "Microbiome-based approaches to personalized nutrition: from gut health to disease prevention.",
      "journal": "Folia microbiologica",
      "abstract": "A complex community of trillions of microorganisms, the human gut microbiome has become a major regulator of health, impacting immune system function, metabolism, digestion, and even brain activity. Recent findings demonstrate how the microbiota is significantly shaped by diet and how the microbiome in turn influences how each person reacts to nutrition. In order to promote disease prevention and long-term health outcomes, this review examines how microbiome-driven approaches are transforming personalized nutrition by going beyond traditional dietary models. The review addresses how dietary elements like fibre, polyphenols, prebiotics, and fermented foods support metabolic activity and microbial diversity. It also discusses the connections between microbial imbalances, or dysbiosis, and illnesses like diabetes, obesity, heart disease, inflammatory bowel disease, and mental health issues. Personalized dietary recommendations based on individual microbiome profiles are becoming more and more possible with the development of high-throughput sequencing, machine learning, and multi-omics tools. Aside from addressing ethical concerns like data protection, affordability, and fair access to individualized interventions, the review also emphasizes the creation of customized probiotics and synbiotics that are made to fit the unique microbiome profiles of each individual. In the end, this review emphasizes how crucial it is to incorporate microbiome science into customized nutrition in order to support preventive healthcare and enhance clinical results.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    },
    {
      "pmid": "PMID:40991041",
      "pmcid": null,
      "title": "Novel antimicrobial peptide HFIAP-1 mutant as a \u03b2-lactamase inhibitor against extended-spectrum \u03b2-lactamases of Escherichia coli: a comprehensive in-silico approach.",
      "journal": "Archives of microbiology",
      "abstract": "Extended-spectrum \u03b2-lactamases in Escherichia coli poses a significant threat for clinicians in tertiary healthcare settings, rendering treatments ineffective with newer \u03b2-lactam-\u03b2-lactamase inhibitors combinations. To overcome this, the present study was conducted to potential \u03b2-lactamase inhibitors, from a library of antimicrobial peptide mutants with enhanced antibacterial potency (~\u20097-16%) as compared to their parent peptides. The study screened five peptides and their mutants based on physicochemical, pharmaco-immunogenic properties through comprehensive knowledge-based and machine-learning algorithms. Molecular docking analyses revealed HFIAP-1_M5 (L33K-W7C-N34C) as the potential inhibitor candidate, that predicted to inhibit\u2009~\u200982% of all the studied ES\u03b2Ls (Class A-D) targets as analysed from the intermolecular interaction profiling. HFIAP-1_M5 exhibited enhanced binding affinities (~\u20090.2-12.0%) than the parent peptides upon forming hydrogen bonds, van-der Waals interactions and salt bridges with crucial residues concerning the catalytic domains of class A [InterPro ID: IPR045155], class B [InterPro ID: IPR001279], class C [InterPro ID: IPR001466] and class D [InterPro ID: IPR001460] of \u03b2-lactamases as defined in the InterPro database. All-atom molecular dynamics simulations, supported by principal component analysis and free energy landscape analysis, confirmed the stability of ES\u03b2Ls-HFIAP-1_M5 showing stable backbone profiles with minimal residue-level fluctuations throughout the simulation timeframe. Binding free energy calculations along with the energy decomposition analysis further highlighted the key residue contributions to complex stabilization. The study holds promise in developing a combination therapy upon augmenting HFIAP-1_M5 with susceptible \u03b2-lactam antibiotics to enhance the therapeutic spectrum of treatment after further experimental validations.",
      "has_fulltext": false,
      "download_success": false,
      "pdf_path": null,
      "error_message": null
    }
  ],
  "llm_analysis_summary": null,
  "visualization_files": []
}